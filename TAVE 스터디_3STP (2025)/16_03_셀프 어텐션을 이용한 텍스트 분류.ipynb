{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMbsJyn0ik7AOZvWvsRoLSU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 1. 멀티 헤드 어텐션"],"metadata":{"id":"EX0PmXpCQTk-"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"1PYIx1lpHwdn","executionInfo":{"status":"ok","timestamp":1743193219772,"user_tz":-540,"elapsed":13669,"user":{"displayName":"김현주/컴퓨터공학부","userId":"13373004077348590592"}}},"outputs":[],"source":["import tensorflow as tf\n","\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, embedding_dim, num_heads=8):\n","        super(MultiHeadAttention, self).__init__()\n","        self.embedding_dim = embedding_dim # d_model\n","        self.num_heads = num_heads\n","\n","        assert embedding_dim % self.num_heads == 0\n","\n","        self.projection_dim = embedding_dim // num_heads\n","        self.query_dense = tf.keras.layers.Dense(embedding_dim)\n","        self.key_dense = tf.keras.layers.Dense(embedding_dim)\n","        self.value_dense = tf.keras.layers.Dense(embedding_dim)\n","        self.dense = tf.keras.layers.Dense(embedding_dim)\n","\n","    def scaled_dot_product_attention(self, query, key, value):\n","        matmul_qk = tf.matmul(query, key, transpose_b=True)\n","        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n","        logits = matmul_qk / tf.math.sqrt(depth)\n","        attention_weights = tf.nn.softmax(logits, axis=-1)\n","        output = tf.matmul(attention_weights, value)\n","        return output, attention_weights\n","\n","    def split_heads(self, x, batch_size):\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, inputs):\n","        # x.shape = [batch_size, seq_len, embedding_dim]\n","        batch_size = tf.shape(inputs)[0]\n","\n","        # (batch_size, seq_len, embedding_dim)\n","        query = self.query_dense(inputs)\n","        key = self.key_dense(inputs)\n","        value = self.value_dense(inputs)\n","\n","        # (batch_size, num_heads, seq_len, projection_dim)\n","        query = self.split_heads(query, batch_size)\n","        key = self.split_heads(key, batch_size)\n","        value = self.split_heads(value, batch_size)\n","\n","        scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n","        # (batch_size, seq_len, num_heads, projection_dim)\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","\n","        # (batch_size, seq_len, embedding_dim)\n","        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embedding_dim))\n","        outputs = self.dense(concat_attention)\n","        return outputs"]},{"cell_type":"markdown","source":["## 2. 인코더 설계하기"],"metadata":{"id":"go7Oz4iJQWil"}},{"cell_type":"code","source":["class TransformerBlock(tf.keras.layers.Layer):\n","    def __init__(self, embedding_dim, num_heads, dff, rate=0.1):\n","        super(TransformerBlock, self).__init__()\n","        self.att = MultiHeadAttention(embedding_dim, num_heads)\n","        self.ffn = tf.keras.Sequential(\n","            [tf.keras.layers.Dense(dff, activation=\"relu\"),\n","             tf.keras.layers.Dense(embedding_dim),]\n","        )\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, inputs, training):\n","        attn_output = self.att(inputs) # 첫번째 서브층 : 멀티 헤드 어텐션\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(inputs + attn_output) # Add & Norm\n","        ffn_output = self.ffn(out1) # 두번째 서브층 : 포지션 와이즈 피드 포워드 신경망\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        return self.layernorm2(out1 + ffn_output) # Add & Norm"],"metadata":{"id":"bP8pSELKQSB3","executionInfo":{"status":"ok","timestamp":1743193219778,"user_tz":-540,"elapsed":12,"user":{"displayName":"김현주/컴퓨터공학부","userId":"13373004077348590592"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## 3. 포지션 임베딩"],"metadata":{"id":"yMKTas9IQvIO"}},{"cell_type":"code","source":["class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n","    def __init__(self, max_len, vocab_size, embedding_dim):\n","        super(TokenAndPositionEmbedding, self).__init__()\n","        self.token_emb = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","        self.pos_emb = tf.keras.layers.Embedding(max_len, embedding_dim)\n","\n","    def call(self, x):\n","        max_len = tf.shape(x)[-1]\n","        positions = tf.range(start=0, limit=max_len, delta=1)\n","        positions = self.pos_emb(positions)\n","        x = self.token_emb(x)\n","        return x + positions"],"metadata":{"id":"vxVLTNuzQUKB","executionInfo":{"status":"ok","timestamp":1743193219780,"user_tz":-540,"elapsed":10,"user":{"displayName":"김현주/컴퓨터공학부","userId":"13373004077348590592"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## 4. 데이터 로드 및 전처리"],"metadata":{"id":"LQjvQm0tRyNa"}},{"cell_type":"code","source":["vocab_size = 20000  # 빈도수 상위 2만개의 단어만 사용\n","max_len = 200  # 문장의 최대 길이\n","\n","(X_train, y_train), (X_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=vocab_size)\n","print('훈련용 리뷰 개수 : {}'.format(len(X_train)))\n","print('테스트용 리뷰 개수 : {}'.format(len(X_test)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rN5q0FXgQzK1","executionInfo":{"status":"ok","timestamp":1743193224917,"user_tz":-540,"elapsed":5136,"user":{"displayName":"김현주/컴퓨터공학부","userId":"13373004077348590592"}},"outputId":"659bb855-2a41-4b96-ef69-a2386b7e0b5b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","훈련용 리뷰 개수 : 25000\n","테스트용 리뷰 개수 : 25000\n"]}]},{"cell_type":"code","source":["X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n","X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)"],"metadata":{"id":"-RfJo8TBR3Dt","executionInfo":{"status":"ok","timestamp":1743193225503,"user_tz":-540,"elapsed":577,"user":{"displayName":"김현주/컴퓨터공학부","userId":"13373004077348590592"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## 5. 트랜스포머를 이용한 IMDB 리뷰 분류"],"metadata":{"id":"K8ILXXoSR3zK"}},{"cell_type":"code","source":["embedding_dim = 32  # 각 단어의 임베딩 벡터의 차원\n","num_heads = 2  # 어텐션 헤드의 수\n","dff = 32  # 포지션 와이즈 피드 포워드 신경망의 은닉층의 크기\n","\n","inputs = tf.keras.layers.Input(shape=(max_len,))\n","embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embedding_dim)\n","x = embedding_layer(inputs)\n","transformer_block = TransformerBlock(embedding_dim, num_heads, dff)\n","x = transformer_block(x, training=True)\n","x = tf.keras.layers.GlobalAveragePooling1D()(x)\n","x = tf.keras.layers.Dropout(0.1)(x)\n","x = tf.keras.layers.Dense(20, activation=\"relu\")(x)\n","x = tf.keras.layers.Dropout(0.1)(x)\n","outputs = tf.keras.layers.Dense(2, activation=\"softmax\")(x)\n","\n","model = tf.keras.Model(inputs=inputs, outputs=outputs)"],"metadata":{"id":"sSseuHlgR5I2","executionInfo":{"status":"ok","timestamp":1743193310938,"user_tz":-540,"elapsed":822,"user":{"displayName":"김현주/컴퓨터공학부","userId":"13373004077348590592"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n","history = model.fit(X_train, y_train, batch_size=32, epochs=2, validation_data=(X_test, y_test))\n","\n","print(\"테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"74q0J-YFR66S","executionInfo":{"status":"ok","timestamp":1743193573267,"user_tz":-540,"elapsed":255461,"user":{"displayName":"김현주/컴퓨터공학부","userId":"13373004077348590592"}},"outputId":"55282043-6dcb-457b-bbd2-8e6ce28d8d78"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 108ms/step - accuracy: 0.6946 - loss: 0.5331 - val_accuracy: 0.8774 - val_loss: 0.2895\n","Epoch 2/2\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 108ms/step - accuracy: 0.9244 - loss: 0.1984 - val_accuracy: 0.8736 - val_loss: 0.3154\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - accuracy: 0.8728 - loss: 0.3172\n","테스트 정확도: 0.8736\n"]}]}]}