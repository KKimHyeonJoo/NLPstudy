{"cells":[{"cell_type":"markdown","metadata":{"id":"0MBZ_OvZQPIU"},"source":["# [자연어처리]\n","# 2주차(2-2). 카운트 기반의 문서 표현(1)\n","\n"]},{"cell_type":"markdown","source":["# 202002961 김현주\n","* 모든 셀 실행 후 제출하시기 바랍니다.\n","* **실습 (2-2-1)**이 있습니다."],"metadata":{"id":"P6UkURyzom6Y"}},{"cell_type":"markdown","metadata":{"id":"8HEzTD_eQPIW"},"source":["## 1. BOW 기반의 카운트 벡터 생성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bhO1nZs3QPIW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726258375855,"user_tz":-540,"elapsed":2701,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"9a4087b5-bd9a-4bdd-835e-da8cf922da84"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Package movie_reviews is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["import nltk\n","nltk.download('movie_reviews')\n","nltk.download('punkt')\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j4tX9_WvQPIY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726258375855,"user_tz":-540,"elapsed":3,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"28fd4dec-d97e-4a89-d21a-194a92038350"},"outputs":[{"output_type":"stream","name":"stdout","text":["#review count: 2000\n","#samples of file ids: ['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', 'neg/cv003_12683.txt', 'neg/cv004_12641.txt', 'neg/cv005_29357.txt', 'neg/cv006_17022.txt', 'neg/cv007_4992.txt', 'neg/cv008_29326.txt', 'neg/cv009_29417.txt']\n","#categories of reviews: ['neg', 'pos']\n","#num of \"neg\" reviews: 1000\n","#num of \"pos\" reviews: 1000\n","#id of the first review: neg/cv000_29416.txt\n","#first review content:\n"," plot : two teen couples go to a church party , drink and then drive . \n","they get into an accident . \n","one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \n","w\n","\n","#sentence tokenization result: ['plot : two teen couples go to a church party , drink and then drive .', 'they get into an accident .']\n","#word tokenization result: ['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an']\n"]}],"source":["from nltk.corpus import movie_reviews\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","\n","print('#review count:', len(movie_reviews.fileids())) #영화 리뷰 문서의 id를 반환\n","print('#samples of file ids:', movie_reviews.fileids()[:10]) #id를 10개까지만 출력\n","print('#categories of reviews:', movie_reviews.categories()) # label, 즉 긍정인지 부정인지에 대한 분류\n","print('#num of \"neg\" reviews:', len(movie_reviews.fileids(categories='neg'))) #label이 부정인 문서들의 id를 반환\n","print('#num of \"pos\" reviews:', len(movie_reviews.fileids(categories='pos'))) #label이 긍정인 문서들의 id를 반환\n","fileid = movie_reviews.fileids()[0] #첫번째 문서의 id를 반환\n","print('#id of the first review:', fileid)\n","print('#first review content:\\n', movie_reviews.raw(fileid)[:200]) #첫번째 문서의 내용을 200자까지만 출력\n","print()\n","print('#sentence tokenization result:', sent_tokenize(movie_reviews.raw(fileid))[:2]) #첫번째 문서를 sentence tokenize한 결과 중 앞 두 문장\n","print('#word tokenization result:', word_tokenize(movie_reviews.raw(fileid))[:20]) #첫번째 문서를 word tokenize한 결과 중 앞 스무 단어"]},{"cell_type":"markdown","source":["**1단계**\n","\n","각 문서에 대해 텍스트 전처리를 수행해 의미가 있는 최고 단위의 리스트로 변환 -> 토큰화, 정제"],"metadata":{"id":"KGyNQSg474hl"}},{"cell_type":"markdown","source":["- 토큰화 :\n","여기서는 단순히 nltkd의 word_tokenize()를 사용하여 토큰화를 수행했다."],"metadata":{"id":"_GKUULXp8KR5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FKyZJRiVQPIY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726258400306,"user_tz":-540,"elapsed":24453,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"d30b33c3-596a-449a-beca-92507a3b1a6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an', 'accident', '.', 'one', 'of', 'the', 'guys', 'dies', ',', 'but', 'his', 'girlfriend', 'continues', 'to', 'see', 'him', 'in', 'her', 'life', ',', 'and', 'has', 'nightmares', '.', 'what', \"'s\", 'the', 'deal', '?', 'watch', 'the']\n"]}],"source":["documents = [word_tokenize(movie_reviews.raw(fileid)) for fileid in movie_reviews.fileids()]\n","print(documents[0][:50]) #첫째 문서의 앞 50개 단어를 출력"]},{"cell_type":"markdown","source":["- 정제 : 정제를 적용하기 위해 word_count를 이용해 단어의 빈도수를 세고, 빈도수 상위 10개의 단어를 출력하도록 했다."],"metadata":{"id":"PC-GPM4J9KA1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dnh2dLOoQPIY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726258400647,"user_tz":-540,"elapsed":351,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"0d88242e-1ab3-4bc2-8c5c-abab9102cdfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["count of ',': 77717, count of 'the': 76276, count of '.': 65876, count of 'a': 37995, count of 'and': 35404, count of 'of': 33972, count of 'to': 31772, count of 'is': 26054, count of 'in': 21611, count of ''s': 18128, "]}],"source":["word_count = {}\n","for text in documents:\n","    for word in text:\n","        word_count[word] = word_count.get(word, 0) + 1\n","\n","sorted_features = sorted(word_count, key=word_count.get, reverse=True)\n","for word in sorted_features[:10]: # 빈도수 상위 10개의 단어 출력\n","    print(f\"count of '{word}': {word_count[word]}\", end=', ')"]},{"cell_type":"markdown","source":["- 정제 : 불용어에 해당하지 않는 토큰과 길이가 2보다 큰 토큰만 추가하도록 하여 특성집합을 구성했다."],"metadata":{"id":"7iLS5pt_8Mda"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VnCiEteiQPIZ"},"outputs":[],"source":["from nltk.corpus import stopwords #일반적으로 분석대상이 아닌 단어들\n","\n","english_stops = set(stopwords.words('english')) #영어 불용어를 가져옴\n","\n","#words() 대신 raw()를 이용해 원문을 가져옴\n","documents = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids()]\n","\n","# stopwords의 적용과 토큰화를 동시에 수행.\n","tokens = [[token for token in word_tokenize(doc) if token not in english_stops and len(token) > 2] for doc in documents]\n","\n","word_count = {}\n","for text in tokens:\n","    for word in text:\n","        word_count[word] = word_count.get(word, 0) + 1"]},{"cell_type":"markdown","source":["**2단계**\n","\n","특성 추출 대상이 되는 단어 집합, 즉 특성 집합을 구성"],"metadata":{"id":"54wCXF3Y-FoM"}},{"cell_type":"code","source":["sorted_features = sorted(word_count, key=word_count.get, reverse=True)\n","\n","print('num of features:', len(sorted_features))\n","for word in sorted_features[:10]:\n","    print(f\"count of '{word}': {word_count[word]}\", end=', ')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tLWhUd1p-DpR","executionInfo":{"status":"ok","timestamp":1726258413195,"user_tz":-540,"elapsed":23,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"c46f061c-8df7-499f-91fb-cc1d5f41f3bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["num of features: 45953\n","count of 'film': 9443, count of 'n't': 6217, count of 'movie': 5671, count of 'one': 5582, count of 'like': 3547, count of 'even': 2556, count of 'good': 2316, count of 'time': 2282, count of 'would': 2264, count of 'story': 2146, "]}]},{"cell_type":"markdown","source":["- 기준에 따라 단어들을 선별할 수 있는데, 여기에서는 빈도를 계산하고 빈도가 높은 단어 1000개만을 추출하여 문서를 표현할 특성으로 사용했다."],"metadata":{"id":"HOA2B0Aa-Xpn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJSgSJL6QPIZ"},"outputs":[],"source":["word_features = sorted_features[:1000] #빈도가 높은 상위 1000개의 단어만 추출하여 features를 구성"]},{"cell_type":"markdown","source":["**3단계**\n","\n","각 문서별로 특성 추출 대상 단어들에 대해 단어의 빈도를 계산해 특성 벡터(카운터 벡터)를 추출"],"metadata":{"id":"rpht1mGq_As1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0hXwhgZSQPIZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726258413195,"user_tz":-540,"elapsed":21,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"43e1d51c-a780-481d-e4f0-9c46dffbf429"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 2, 0, 1, 0]\n"]}],"source":["def document_features(document, word_features):\n","    word_count = {}\n","    for word in document: #document에 있는 단어들에 대해 빈도수를 먼저 계산\n","        word_count[word] = word_count.get(word, 0) + 1\n","\n","    features = []\n","    for word in word_features: #word_features의 단어에 대해 계산된 빈도수를 feature에 추가\n","        features.append(word_count.get(word, 0)) #빈도가 없는 단어는 0을 입력\n","    return features\n","\n","word_features_ex = ['one', 'two', 'teen', 'couples', 'solo']\n","doc_ex = ['two', 'two', 'couples']\n","print(document_features(doc_ex, word_features_ex))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y20O-ylCQPIa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726258413546,"user_tz":-540,"elapsed":366,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"dea403fe-2699-4652-9c0e-8bbff0f04d1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["(film, 6), (n't, 6), (movie, 6), (one, 3), (like, 3), (even, 3), (good, 2), (time, 0), (would, 1), (story, 0), (much, 0), (character, 2), (also, 1), (get, 3), (characters, 1), (two, 2), (first, 0), (see, 2), (way, 2), (well, 1), "]}],"source":["feature_sets = [document_features(d, word_features) for d in tokens]\n","\n","# 첫째 feature set의 내용을 앞 20개만 word_features의 단어와 함께 출력\n","for i in range(20):\n","    print(f'({word_features[i]}, {feature_sets[0][i]})', end=', ')"]},{"cell_type":"markdown","source":["- word_features의 단어는 빈도가 높은 순서대로 정렬되어 있기 때문에 위에서 20개 값을 출력해보면 모두 0으로 나오는 것을 확인할 수 있다."],"metadata":{"id":"iLkRwRqI_ZJr"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"roqy5JoaQPIa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726258413546,"user_tz":-540,"elapsed":6,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"a093854c-5aaf-408f-e18f-6a4d8594ae3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}],"source":["print(feature_sets[0][-20:])"]},{"cell_type":"markdown","metadata":{"id":"3zNZ_IBNQPIa"},"source":["## 2. 사이킷런을 이용한 카운트 벡터 생성"]},{"cell_type":"markdown","metadata":{"id":"80KdYKyrQPIa"},"source":["### CountVectorizer\n","\n","http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6zgO2b5bQPIa"},"outputs":[],"source":["# data 준비, movie_reviews.raw()를 사용하여 raw text를 추출\n","reviews = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mVYPeCi8QPIb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726258413881,"user_tz":-540,"elapsed":3,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"efdd34d6-9f7e-4c93-c7ca-49ccf5a26e89"},"outputs":[{"output_type":"stream","name":"stdout","text":["CountVectorizer(vocabulary=['film', \"n't\", 'movie', 'one', 'like', 'even',\n","                            'good', 'time', 'would', 'story', 'much',\n","                            'character', 'also', 'get', 'characters', 'two',\n","                            'first', 'see', 'way', 'well', 'could', 'make',\n","                            'really', 'films', 'little', 'life', 'plot',\n","                            'people', 'scene', 'bad', ...])\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","#cv = CountVectorizer() #모든 매개변수에 디폴트 값을 사용하는 경우\n","\n","#앞에서 생성한 word_features를 이용하여 특성 집합을 지정하는 경우\n","cv = CountVectorizer(vocabulary=word_features)\n","\n","#cv = CountVectorizer(max_features=1000) #특성 집합을 지정하지 않고 최대 특성의 수를 지정하는 경우\n","print(cv) #객체에 사용된 인수들을 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qsVdPQQYQPIb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726258415037,"user_tz":-540,"elapsed":1158,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"3915279f-b00e-46dd-92c9-92c2afeefe42"},"outputs":[{"output_type":"stream","name":"stdout","text":["['film' \"n't\" 'movie' 'one' 'like' 'even' 'good' 'time' 'would' 'story'\n"," 'much' 'character' 'also' 'get' 'characters' 'two' 'first' 'see' 'way'\n"," 'well']\n","['film', \"n't\", 'movie', 'one', 'like', 'even', 'good', 'time', 'would', 'story', 'much', 'character', 'also', 'get', 'characters', 'two', 'first', 'see', 'way', 'well']\n"]}],"source":["reviews_cv = cv.fit_transform(reviews) #reviews를 이용하여 count vector를 학습하고, 변환\n","print(cv.get_feature_names_out()[:20]) # count vector에 사용된 feature 이름을 반환\n","print(word_features[:20]) # 비교를 위해 출력"]},{"cell_type":"markdown","source":["- 카운터 벡터의 형태가 2000x1000인 sparse matrix인 것을 알수 있다.\n","- 카운터 벡터의 대부분의 값이 0이므로 단어의 희소성으로 인해 (0, 0)과 같은 형태로 표현하면 공간을 효율적으로 사용할 수 있다."],"metadata":{"id":"zghxK9zJAbBA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_V124NBQPIb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726258415037,"user_tz":-540,"elapsed":7,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"56dfecf9-7efe-4d3a-cecb-ada16f32d8fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["#type of count vectors: <class 'scipy.sparse._csr.csr_matrix'>\n","#shape of count vectors: (2000, 1000)\n","#sample of count vector:\n","  (0, 0)\t6\n","  (0, 2)\t6\n","  (0, 3)\t3\n","  (0, 4)\t3\n","  (0, 5)\t3\n","  (0, 6)\t2\n","  (0, 8)\t1\n"]}],"source":["print('#type of count vectors:', type(reviews_cv))\n","print('#shape of count vectors:', reviews_cv.shape)\n","print('#sample of count vector:')\n","print(reviews_cv[0, :10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sMimZoNDQPIb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726258415037,"user_tz":-540,"elapsed":6,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"1e6b7886-b92d-4c34-8455-bf7e6d16ddf3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<2000x1000 sparse matrix of type '<class 'numpy.int64'>'\n","\twith 253277 stored elements in Compressed Sparse Row format>"]},"metadata":{},"execution_count":15}],"source":["reviews_cv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1hHNMbBFQPIb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726258415037,"user_tz":-540,"elapsed":5,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"ce9e1e57-8b92-4cbf-eb3b-cd98ddcdf691"},"outputs":[{"output_type":"stream","name":"stdout","text":["film:6, n't:0, movie:6, one:3, like:3, even:3, good:2, time:0, would:1, story:0, much:0, character:2, also:1, get:3, characters:1, two:2, first:0, see:2, way:3, well:1, "]}],"source":["for word, count in zip(cv.get_feature_names_out()[:20], reviews_cv[0].toarray()[0, :20]):\n","    print(f'{word}:{count}', end=', ')"]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"7KcGBvN9oumi"}},{"cell_type":"markdown","source":["# **[[실습 2-2-1]]**\n","## 코드 셀 위에 이를 설명하는 **마크다운 텍스트를 3개 이상 추가**하시오. (포매팅을 하지는 않아도 됨)\n","* 코드 작동에 대한 설명 혹은 코드 결과에 대한 설명 등\n","\n","예시)"],"metadata":{"id":"tpqUSrtNSwF0"}},{"cell_type":"markdown","source":["\n","\n","### 특성의 값을 단어와 함께 보고 싶다면,"],"metadata":{"id":"2A513CVkohVw"}},{"cell_type":"code","source":["for word, count in zip(cv.get_feature_names_out()[:20], reviews_cv[0].toarray()[0, :20]):\n","    print(f'{word}:{count}', end=', ')"],"metadata":{"id":"B-RGGdavoXLT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726258415037,"user_tz":-540,"elapsed":4,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"1a31a6be-c822-487c-dd81-adb3b68cf761"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["film:6, n't:0, movie:6, one:3, like:3, even:3, good:2, time:0, would:1, story:0, much:0, character:2, also:1, get:3, characters:1, two:2, first:0, see:2, way:3, well:1, "]}]},{"cell_type":"markdown","source":["### 0번째 문서에 대해 20번째 feature 까지의 값을 살펴보았다.\n","* film은 6번 등장하였고, n't는 0번 등장하였다. 이처럼 feature로 사용된 단어가 몇 번 등장했는지 횟수가 담긴 matrix가 만들어졌음을 알 수 있다."],"metadata":{"id":"4zQP0Wxwpcep"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"g5GpJrs8FIFg"}},{"cell_type":"markdown","source":["# [파일] -> [다운로드] -> [.ipynb 다운로드]"],"metadata":{"id":"0290VEuY9Rgc"}}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":true,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}