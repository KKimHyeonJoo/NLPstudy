{"cells":[{"cell_type":"markdown","metadata":{"id":"BmABW6vCzWcJ"},"source":["# [자연어처리]\n","# 5주차(5-1). 차원 축소(1)\n","\n","\n","\n"]},{"cell_type":"markdown","source":["# 202002961 김현주"],"metadata":{"id":"5we6SKl61jX1"}},{"cell_type":"markdown","source":["# 이제 Colab 사용에 모든 수강생분들이 실행에는 어느정도 익숙해 졌을 거라 생각됩니다!\n","> ## 중간 중간 **'### ... 이 부분을 완성하시오'** 라는 부분의 코드를 완성해 보기 바랍니다. (강의 자료를 참고하여 '???' 부분을 작성해 보시기 바랍니다.)\n","\n","\n","\n"],"metadata":{"id":"oLw4XETF1mbE"}},{"cell_type":"markdown","metadata":{"id":"jNgIfKg8zWcL"},"source":["## PCA를 이용한 차원 축소\n","\n"]},{"cell_type":"markdown","source":["데이터 셋 준비 (우리에게 익숙한 20newsgroups)"],"metadata":{"id":"gCb5DPXUGaak"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"SWco5iOPzWcM","executionInfo":{"status":"ok","timestamp":1728243228512,"user_tz":-540,"elapsed":6318,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}}},"outputs":[],"source":["from sklearn.datasets import fetch_20newsgroups\n","\n","#20개의 토픽 중 선택하고자 하는 토픽을 리스트로 생성\n","categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n","\n","#학습 데이터셋을 가져옴\n","#메일 내용에서 hint가 되는 부분을 삭제 - 순수하게 내용만으로 분류\n","newsgroups_train = fetch_20newsgroups(subset='train',\n","                                      remove=('headers', 'footers', 'quotes'),\n","                                      categories=categories)\n","#검증 데이터셋을 가져옴\n","newsgroups_test = fetch_20newsgroups(subset='test',\n","                                     remove=('headers', 'footers', 'quotes'),\n","                                     categories=categories)\n","\n","X_train = newsgroups_train.data   #학습 데이터셋\n","y_train = newsgroups_train.target #학습 데이터셋\n","\n","X_test = newsgroups_test.data     #검증 데이터셋\n","y_test = newsgroups_test.target   #검증 데이터셋"]},{"cell_type":"markdown","source":["전처리\n","* 토큰화, 불용어처리, 스테밍\n"],"metadata":{"id":"d03KqvJwGe_k"}},{"cell_type":"code","source":["import nltk\n","\n","nltk.download('stopwords')"],"metadata":{"id":"RJKk1hCjGYwT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728243229774,"user_tz":-540,"elapsed":1263,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"52ba6dff-ce7e-4eff-9ff4-120969fad8f5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["from nltk.tokenize import RegexpTokenizer\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","\n","RegTok = RegexpTokenizer(\"[\\w']{3,}\") # 정규포현식으로 토크나이저를 정의\n","english_stops = set(stopwords.words('english')) #영어 불용어를 가져옴\n","stemmer = PorterStemmer() # 스테머로 포터스테머 사용\n","\n","def my_tokenizer(text):\n","    tokens = RegTok.tokenize(text)\n","    # stopwords 제외\n","    words = [word for word in tokens if word not in english_stops]\n","    # portr stemmer 적용\n","    features = [stemmer.stem(token) for token in words]\n","    return features"],"metadata":{"id":"SmkiLmtOGUEj","executionInfo":{"status":"ok","timestamp":1728243229774,"user_tz":-540,"elapsed":3,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 약간의 시간(약 30초)이 소요됩니다.\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","#tfidf = TfidfVectorizer(tokenizer=my_tokenizer, max_features=2000, min_df=5, max_df=0.5)\n","# 토큰화 외에 아무것도 적용하지 않은 채로 확인\n","tfidf = TfidfVectorizer(tokenizer=my_tokenizer) ### ... 이 부분을 완성하시오 (강의 자료를 참고하여 '???' 부분을 작성해 보시기 바랍니다.)\n","\n","X_train_tfidf = tfidf.fit_transform(X_train) # train set을 변환\n","X_test_tfidf = tfidf.transform(X_test) # test set을 변환"],"metadata":{"id":"vwcetq65SOa6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728243260118,"user_tz":-540,"elapsed":30347,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"9cb9c1a4-4fd2-4903-8824-83f38968a21a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["print('Original tfidf matrix shape:', X_train_tfidf.shape)"],"metadata":{"id":"62cFIpxfIwO0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728243260118,"user_tz":-540,"elapsed":5,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"fdcafda9-f5ab-4665-a7b4-df40cf34e43f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Original tfidf matrix shape: (2034, 20085)\n"]}]},{"cell_type":"markdown","source":["(방법 1) 차원 축소 방법을 적용하기 전의 Logistic Regression을 이용한 분류 성능 확인"],"metadata":{"id":"9Zv8i3kEH9Lb"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"ofJSNPVozWcN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728243263086,"user_tz":-540,"elapsed":2971,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"f53a5852-c09d-45c1-db69-7e1f3a37ea96"},"outputs":[{"output_type":"stream","name":"stdout","text":["#Train set score: 0.962\n","#Test set score: 0.761\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","\n","LR_clf = LogisticRegression() #분류기 선언\n","LR_clf.fit(X_train_tfidf, y_train) # train data를 이용하여 분류기를 학습\n","print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train)))\n","print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test)))"]},{"cell_type":"markdown","source":["(방법 2) 차원 축소 방법을 적용한 후의 Logistic Regression을 이용한 분류 성능 확인\n","* 차원 축소 방법인 PCA를 적용\n","* 2000차원으로 축소한 뒤 Logistic Regression을 이용한 분류 성능 확인"],"metadata":{"id":"Gfif_glrNKfd"}},{"cell_type":"markdown","metadata":{"id":"i8h8xrw9zWcN"},"source":["https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"]},{"cell_type":"markdown","source":["explained_variance_ratio_\n","- Percentage of variance explained by each of the selected components.\n","- If n_components is not set then all components are stored and the sum of the ratios is equal to 1.0.\n","- 각각의 새로운 축에 대해, 축소 전 분산에 대한 비율\n","- 만일 새로운 축들이 원래의 분산을 모두 설명해준다면 explained_variance_ratio_의 합은 1이 될 것임"],"metadata":{"id":"-m5dR3cbI04Z"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"3C-uLYPbzWcO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728243336048,"user_tz":-540,"elapsed":72966,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"0227c19b-2233-4e00-d46b-48110fc73c08"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original tfidf matrix shape: (2034, 20085)\n","PCA Converted matrix shape: (2034, 2000)\n","Sum of explained variance ratio: 1.000\n"]}],"source":["# 약간의 시간(약 30초)이 소요됩니다.\n","from sklearn.decomposition import PCA\n","\n","#  20,085 차원을 2,000 차원으로 축소\n","pca = PCA(n_components=2000, random_state=7) ### ... 이 부분을 완성하시오 (강의 자료를 참고하여 '???' 부분을 작성해 보시기 바랍니다.)\n","\n","X_train_pca = pca.fit_transform(X_train_tfidf.toarray())\n","X_test_pca = pca.transform(X_test_tfidf.toarray())\n","\n","print('Original tfidf matrix shape:', X_train_tfidf.shape)\n","print('PCA Converted matrix shape:', X_train_pca.shape)\n","print('Sum of explained variance ratio: {:.3f}'.format(pca.explained_variance_ratio_.sum())) ### ... 이 부분을 완성하시오 (강의 자료를 참고하여 '???' 부분을 작성해 보시기 바랍니다.)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"5oW4iq1IzWcO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728243337196,"user_tz":-540,"elapsed":1153,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"69a828b1-a9f8-4f18-a4d9-663fa2a9106b"},"outputs":[{"output_type":"stream","name":"stdout","text":["#Train set score: 0.962\n","#Test set score: 0.760\n"]}],"source":["# PCA로 차원 축소된 X 데이터 이용\n","LR_clf.fit(X_train_pca, y_train) ### ... 이 부분을 완성하시오 (강의 자료를 참고하여 '???' 부분을 작성해 보시기 바랍니다.)\n","\n","print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_pca, y_train))) ### ... 이 부분을 완성하시오 (강의 자료를 참고하여 '???' 부분을 작성해 보시기 바랍니다.)\n","print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_pca, y_test))) ### ... 이 부분을 완성하시오 (강의 자료를 참고하여 '???' 부분을 작성해 보시기 바랍니다.)"]},{"cell_type":"markdown","source":["(방법 3) 특성 선택 방식인 라쏘 회귀를 이용\n","* lasso_clf = LogisticRegression(penalty='l1', solver='liblinear', C=1)\n","* 차원을 축소"],"metadata":{"id":"_EpP6b_BLEcF"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"2NLdjV-ZzWcO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728243337196,"user_tz":-540,"elapsed":4,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"96f8c9e9-c612-471a-875a-294c9802a10d"},"outputs":[{"output_type":"stream","name":"stdout","text":["#Train set score: 0.790\n","#Test set score: 0.718\n","#Used features count: 321 out of 20085\n"]}],"source":["lasso_clf = LogisticRegression(penalty='l1', solver='liblinear', C=1)\n","lasso_clf.fit(X_train_tfidf, y_train)\n","\n","print('#Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n","print('#Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n","\n","import numpy as np\n","# 계수(coefficient) 중에서 0이 아닌 것들의 개수를 출력\n","print('#Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1])"]},{"cell_type":"markdown","source":["(방법 4) 특성 추출 추출 방식인 PCA를 이용\n","- 차원의 수를 322개로 축소\n","- pca = PCA(n_components=322, random_state=7)\n"],"metadata":{"id":"QECbJup6MxJL"}},{"cell_type":"code","execution_count":10,"metadata":{"id":"B28LMdm2zWcO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728243354553,"user_tz":-540,"elapsed":17360,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"2d6075ee-9411-47e0-b1c4-e70e7fd22844"},"outputs":[{"output_type":"stream","name":"stdout","text":["PCA Converted X shape: (2034, 322)\n","Sum of explained variance ratio: 0.438\n","#Train set score: 0.871\n","#Test set score: 0.746\n"]}],"source":["# 약간의 시간(약 30초)이 소요됩니다.\n","pca = PCA(n_components=322, random_state=7) ### ... 이 부분을 완성하시오 (강의 자료를 참고하여 '???' 부분을 작성해 보시기 바랍니다.)\n","\n","X_train_pca = pca.fit_transform(X_train_tfidf.toarray())\n","X_test_pca = pca.transform(X_test_tfidf.toarray())\n","\n","# 322차원으로 줄어든 것을 확인\n","print('PCA Converted X shape:', X_train_pca.shape) ### ... 이 부분을 완성하시오 (강의 자료를 참고하여 '???' 부분을 작성해 보시기 바랍니다.)\n","print('Sum of explained variance ratio: {:.3f}'.format(pca.explained_variance_ratio_.sum()))  ### ... 이 부분을 완성하시오 (강의 자료를 참고하여 '???' 부분을 작성해 보시기 바랍니다.)\n","# 2,000개에 비해 정보량이 절반 이하로 줄어들었음\n","\n","LR_clf.fit(X_train_pca, y_train)  ### ... 이 부분을 완성하시오 (강의 자료를 참고하여 '???' 부분을 작성해 보시기 바랍니다.) # 322차원으로 줄어든 것을 확인\n","print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_pca, y_train)))  ### ... 이 부분을 완성하시오 (강의 자료를 참고하여 '???' 부분을 작성해 보시기 바랍니다.)\n","print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_pca, y_test))) ### ... 이 부분을 완성하시오 (강의 자료를 참고하여 '???' 부분을 작성해 보시기 바랍니다.)\n","# 라쏘 회귀분석(0.718)을 이용한 특성 선택보다 더 좋은 성능을 보임"]},{"cell_type":"markdown","source":["(방법 5) 그러면 322개보다 더 줄여서 100개만 이용해보자.\n","- 여전히 라쏘 회귀분석보다 좋은지 확인\n"],"metadata":{"id":"OnYKkRBHMl6Q"}},{"cell_type":"code","execution_count":11,"metadata":{"id":"xBXkNpbCzWcP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728243365348,"user_tz":-540,"elapsed":10799,"user":{"displayName":"ᄒᄒ","userId":"18137854489485594855"}},"outputId":"0509ec4c-5ff4-4518-e13e-de0f1d12ea49"},"outputs":[{"output_type":"stream","name":"stdout","text":["PCA Converted X shape: (2034, 100)\n","Sum of explained variance ratio: 0.211\n","#Train set score: 0.808\n","#Test set score: 0.738\n"]}],"source":["# 약간의 시간(약 30초)이 소요됩니다.\n","pca = PCA(n_components=100, random_state=7)\n","\n","X_train_pca = pca.fit_transform(X_train_tfidf.toarray())\n","X_test_pca = pca.transform(X_test_tfidf.toarray())\n","print('PCA Converted X shape:', X_train_pca.shape)\n","print('Sum of explained variance ratio: {:.3f}'.format(pca.explained_variance_ratio_.sum()))\n","\n","LR_clf.fit(X_train_pca, y_train)\n","print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_pca, y_train)))\n","print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_pca, y_test)))\n","# 라쏘 회귀분석(0.718)을 이용한 특성 선택보다 더 좋은 성능을 보임"]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"slOnCHs5Mhio"}},{"cell_type":"markdown","source":["# **[[실습 5-1-1]]** 방법 1 ~ 방법 5의 Test set score를 비교하고, 어떤 방법이 가장 좋은지 결론을 내리시오. 그리고 그 이유를 추측해 보시오."],"metadata":{"id":"TctTtgF52BxA"}},{"cell_type":"markdown","source":["- 방법 1의 Test set score: 0.761\n","- 방법 2의 Test set score: 0.760\n","- 방법 3의 Test set score: 0.718\n","- 방법 4의 Test set score: 0.746\n","- 방법 5의 Test set score: 0.738\n","\n","\n","비교 결과 작성:\n","> 0.761 (방법1) > 0.760 (방법2) > 0.746 (방법4) > 0.738 (방법5) > 0.718 (방법3)\n","\n","따라서 방법1이 가장 좋다. 이러한 차이가 발생한 이유는 차원 축소를 적용하지 않은 방법 1이 가장 큰 차원을 그대로 활용했기 때문이다.\n","\n","차원 축소를 적용한 방법들을 비교하면, PCA를 이용한 방법2, 방법4, 방법5의 성능이 라쏘 회귀를 이용한 방법3보다 더 좋은 성능을 보였다. 또한 PCA를 이용한 방법은 차원의 크기를 라쏘 회귀보다 작게 했음에도 좋은 성능을 보였다. 이는 PCA는 데이터의 분산을 최대로 보존하는 새로운 축을 찾아 변환하여 차원을 축소하는데 이때 정보가 최대한 유지되도록하기 때문이다."],"metadata":{"id":"vpyBCTOlOJjJ"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"R2gft5J8Mgna"}},{"cell_type":"markdown","source":["# [파일] -> [다운로드] -> [.ipynb 다운로드]"],"metadata":{"id":"iWmyIF9717_u"}}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":true,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"165px"},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}